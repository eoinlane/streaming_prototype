{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, RDD\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pykafka import KafkaClient\n",
    "import json\n",
    "\n",
    "# Create a local StreamingContext with two working thread and batch interval of 1 second\n",
    "#sc = SparkContext(\"spark://server1:7077\", \"pyspark\")\n",
    "\n",
    "\n",
    "conf = SparkConf().setAppName(\"Sales Order Unified Profile Update\").setMaster(\"spark://server1:7077\")\n",
    "conf.set(\"spark.cores.max\", 9)\n",
    "conf.set(\"spark.cassandra.connection.host\", \"server4\")\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "streamingContext = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from cassandra.query import BatchStatement\n",
    "\n",
    "class SimpleClient(object):\n",
    "    session = None\n",
    "    createProfileStatement = None\n",
    "    updateSalesOrderStatement = None\n",
    "    \n",
    "    batch = None\n",
    "    \n",
    "    session = None\n",
    "\n",
    "    def connect(self):\n",
    "        if(self.session is None):\n",
    "            cluster = Cluster(['server4.bigdata.ibm.com','server5.bigdata.ibm.com','server6.bigdata.ibm.com'])\n",
    "            self.session = cluster.connect()\n",
    "        return self.session\n",
    "        #the key space is test now\n",
    "        #self.session.execute(\"use test\")\n",
    "        #self.createProfileStatement = self.session.prepare(\"insert into customer_product(customer, product, date) values(?,?,?) if not exists\")\n",
    "        #self.updateSalesOrderStatement = self.session.prepare(\"update customer_product set orders[?] = {qty: ?, unitAmt: ?} where customer = ? and product = ? and date = ?\")\n",
    "\n",
    "    def close(self):\n",
    "        print 'close'\n",
    "        #self.session.cluster.shutdown()\n",
    "        \n",
    "    def createProfile(self, args):\n",
    "        #self.batch.add(self.createProfileStatement, args)\n",
    "        self.session.execute(self.createProfileStatement, args)\n",
    "    \n",
    "    def updateSalesOrder(self, args):\n",
    "        #self.batch.add(self.updateSalesOrderStatement, args)\n",
    "        self.session.execute(self.updateSalesOrderStatement, args)\n",
    "    \n",
    "    def execute(self, statement, parameters=[]):\n",
    "        preparedStatement = self.session.prepare(statement)\n",
    "        return self.session.execute(preparedStatement, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change localhost:2181 to server7 or zookeeper on server1?\n",
    "stream = KafkaUtils.createStream(streamingContext, 'server1.bigdata.ibm.com:2181', \"raw-data-to-profile-update\", {'event' :3})\n",
    "\n",
    "def processEvent(client, event):\n",
    "    #print event\n",
    "    customer = event['Customer']\n",
    "    product = event['Product']\n",
    "    date = event['XactionDate'][0:10]\n",
    "    time = event['XactionDate'][11:19]\n",
    "    qty = event['Qty']\n",
    "    unitAmt = event['UnitAmt']\n",
    "    #insert row if not exist\n",
    "    #print \"inserting profile\"\n",
    "    #client.createProfile([customer, product, date])\n",
    "    client.execute(\"insert into test.customer_product(customer, product, date) values(?,?,?) if not exists\", [customer, product, date])\n",
    "    #insert sales order\n",
    "    #print \"inerting sales order\"\n",
    "    client.execute(\"update test.customer_product set orders[?] = {qty: ?, unitAmt: ?} where customer = ? and product = ? and date = ?\",\n",
    "                  [time, qty, unitAmt, customer, product, date])\n",
    "    #client.updateSalesOrder([time, qty, unitAmt, customer, product, date])\n",
    "    #send to profile update service\n",
    "    profile = {'customer': customer, 'product': product, 'date': date}\n",
    "    \n",
    "    result = client.execute(\"select * from test.customer_product where customer = ? and product = ? and date = ?\", [customer, product, date])\n",
    "    row = result[0]\n",
    "    profile['LTDSalesCount'] = 0\n",
    "    profile['LTDSalesQty'] = 0\n",
    "    profile['LTDSalesAmt'] = 0.0\n",
    "    profile['AvgSalesAmt'] = 0.0\n",
    "    profile['AvgSalesQty'] = 0.0\n",
    "    \n",
    "    for key in row.orders.iterkeys():\n",
    "        value = row.orders.get(key)\n",
    "        profile['LTDSalesCount'] += 1\n",
    "        profile['LTDSalesQty'] += value.qty\n",
    "        profile['LTDSalesAmt'] += value.qty * value.unitamt\n",
    "        \n",
    "    if(profile['LTDSalesQty'] > 0.0 and profile['LTDSalesCount'] > 0):\n",
    "        profile['AvgSalesAmt'] = profile['LTDSalesAmt'] / profile['LTDSalesQty']\n",
    "        profile['AvgSalesQty'] = float(profile['LTDSalesQty']) / profile['LTDSalesCount']\n",
    "    \n",
    "        #TODO: calcualate score\n",
    "        profile['Score'] = 1\n",
    "    \n",
    "        client.execute(\"\"\"update test.customer_product \n",
    "            set LTDSalesAmt = ?, LTDSalesQty = ?, LTDSalesCount = ?, AvgSalesAmt = ?, AvgSalesQty = ?\n",
    "            where customer = ? and product = ? and date = ?\"\"\",\n",
    "                    [profile['LTDSalesAmt'], profile['LTDSalesQty'], profile['LTDSalesCount'], \n",
    "                    profile['AvgSalesAmt'], profile['AvgSalesQty'], \n",
    "                    profile['customer'], profile['product'], profile['date']])\n",
    "    \n",
    "\n",
    "    return profile\n",
    "\n",
    "def processPartition(iter):\n",
    "    try:\n",
    "        #cassandra connection\n",
    "        client = SimpleClient()\n",
    "        client.connect()\n",
    "        \n",
    "        i = 0\n",
    "        for record in iter:\n",
    "            event = processEvent(client, json.loads(record[1]))\n",
    "            i += 1\n",
    "    finally:\n",
    "        client.close()\n",
    "        print '######## persist ' + str(i) + ' events ,last event is ' +  str(event)\n",
    "\n",
    "def processRDD(rdd):\n",
    "    rdd.foreachPartition(processPartition)\n",
    "    \n",
    "stream.foreachRDD(processRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "streamingContext.start()             # Start the computation\n",
    "streamingContext.awaitTermination()  # Wait for the computation to terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
