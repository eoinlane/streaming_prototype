{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, RDD\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pykafka import KafkaClient\n",
    "import json\n",
    "\n",
    "# Create a local StreamingContext with two working thread and batch interval of 1 second\n",
    "#sc = SparkContext(\"spark://server1:7077\", \"pyspark\")\n",
    "\n",
    "\n",
    "conf = SparkConf().setAppName(\"Sales Order RAW Data\").setMaster(\"spark://server1:7077\")\n",
    "conf.set(\"spark.cores.max\", 3)\n",
    "conf.set(\"spark.cassandra.connection.host\", \"server4\")\n",
    "#conf.set(\"spark.executor.extraClassPath\", \"/root/spark-cassandra-connector-assembly-1.5.0-M1-SNAPSHOT.jar\")\n",
    "#conf.set(\"spark.executor.extraClassPath\", \"/root/spark-streaming-kafka-assembly_2.10-1.5.0.jar\")\n",
    "#conf.set(\"spark.executor.extraClassPath\", \"/root/kafka_2.10-0.8.2.1/libs/kafka_2.10-0.8.2.1.jar\")\n",
    "#conf.set(\"spark.executor.extraClassPath\", \"/root/kafka_2.10-0.8.2.1/libs/zkclient-0.3.jar\")\n",
    "\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "streamingContext = StreamingContext(sc, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from cassandra.query import BatchStatement\n",
    "\n",
    "class SimpleClient(object):\n",
    "    session = None\n",
    "    createProfileStatement = None\n",
    "    updateSalesOrderStatement = None\n",
    "    \n",
    "    batch = None\n",
    "\n",
    "    def connect(self, nodes):\n",
    "        cluster = Cluster(nodes)\n",
    "        metadata = cluster.metadata\n",
    "        self.session = cluster.connect()\n",
    "        #the key space is test now\n",
    "        self.session.execute(\"use test\")\n",
    "        self.createProfileStatement = self.session.prepare(\"insert into customer_product(customer, product, date) values(?,?,?) if not exists\")\n",
    "        self.updateSalesOrderStatement = self.session.prepare(\"update customer_product set orders[?] = {qty: ?, unitAmt: ?} where customer = ? and product = ? and date = ?\")\n",
    "\n",
    "    def close(self):\n",
    "        self.session.cluster.shutdown()\n",
    "        \n",
    "    def createProfile(self, args):\n",
    "        #self.batch.add(self.createProfileStatement, args)\n",
    "        self.session.execute(self.createProfileStatement, args)\n",
    "    \n",
    "    def updateSalesOrder(self, args):\n",
    "        #self.batch.add(self.updateSalesOrderStatement, args)\n",
    "        self.session.execute(self.updateSalesOrderStatement, args)\n",
    "    \n",
    "    def execute(self, statement, parameters=[]):\n",
    "        preparedStatement = self.session.prepare(statement)\n",
    "        return self.session.execute(preparedStatement, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change localhost:2181 to server7 or zookeeper on server1?\n",
    "stream = KafkaUtils.createStream(streamingContext, 'server1.bigdata.ibm.com:2181', \"raw-data-to-cassandra\", {'event' :1})\n",
    "\n",
    "def processEvent(client, producer, event):\n",
    "    #print event\n",
    "    customer = event['Customer']\n",
    "    product = event['Product']\n",
    "    date = event['XactionDate'][0:10]\n",
    "    time = event['XactionDate'][11:19]\n",
    "    qty = event['Qty']\n",
    "    unitAmt = event['UnitAmt']\n",
    "    #insert row if not exist\n",
    "    #print \"inserting profile\"\n",
    "    #client.createProfile([customer, product, date])\n",
    "    client.execute(\"insert into customer_product(customer, product, date) values(?,?,?) if not exists\", [customer, product, date])\n",
    "    #insert sales order\n",
    "    #print \"inerting sales order\"\n",
    "    client.execute(\"update customer_product set orders[?] = {qty: ?, unitAmt: ?} where customer = ? and product = ? and date = ?\",\n",
    "                  [time, qty, unitAmt, customer, product, date])\n",
    "    #client.updateSalesOrder([time, qty, unitAmt, customer, product, date])\n",
    "    #send to profile update service\n",
    "    profile = {'customer': customer, 'product': product, 'date': date}\n",
    "    producer.produce([json.dumps(profile)])\n",
    "    #print \"done\"\n",
    "    return event\n",
    "\n",
    "def processPartition(iter):\n",
    "    try:\n",
    "        #cassandra connection\n",
    "        client = SimpleClient()\n",
    "        client.connect(['server4.bigdata.ibm.com','server5.bigdata.ibm.com','server6.bigdata.ibm.com'])\n",
    "        #print 'connected'\n",
    "        #kafka connection\n",
    "        kafkaClient = KafkaClient(hosts=\"server7.bigdata.ibm.com:9092,server8.bigdata.ibm.com:9092,server9.bigdata.ibm.com:9092\")\n",
    "        topic = kafkaClient.topics['profile']\n",
    "        producer = topic.get_producer()\n",
    "        \n",
    "        i = 0\n",
    "        for record in iter:\n",
    "            event = processEvent(client, producer, json.loads(record[1]))\n",
    "            i += 1\n",
    "    finally:\n",
    "        client.close()\n",
    "        print '######## persist ' + str(i) + ' events ,last event is ' +  str(event)\n",
    "\n",
    "def processRDD(rdd):\n",
    "    rdd.foreachPartition(processPartition)\n",
    "    \n",
    "stream.foreachRDD(processRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "streamingContext.start()             # Start the computation\n",
    "streamingContext.awaitTermination()  # Wait for the computation to terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
